\section{Overview of spatial audio techniques}
Spatial audio aims at the recreation or the synthesis of a sound scene, so that the human listener perceives the spatial characteristics of the desired acoustic environment \cite{Zhang2017}.
The sound scene may contain several sources of sound, termed generally as \emph{audio objects}.
\emph{Sound field reproduction} achieves this by applying an arrangement of fix positioned loudspeakers, so that the sum of the sound waves emerging from the individual loudspeakers generate the impression of virtual audio object.
Alternatively \emph{binaural rendering} applies a headphone for the reproduction of localization cues for the human auditory system directly at the ears of the listener.
These cues include the inter-aural time and level differences (ITD and ILD), the head-related transfer function (HRTF) due the anthropometry of the listener, dynamic cues due to the movement of the listener's head and several environment scattering cues, which all are combined by the human brain, generating the perceived spatial impression \cite{Blauert1983}.
The present thesis considers only spatial audio by loudspeakers.

\paragraph{Stereophony:}
Sound field reproduction has been the subject of excessive study and development over the second half of the XX. century, starting with the work of Blumlein, who introduced the first two-loudspeakers system in 1931 (along with the related recording, transmission and playback methodology) and thereby creating the basics of \emph{stereophony} \cite{Blumlein1932, Alexander2000}.
Blumlein's invention was first put to practical use in the 1950's, and since then stereophony has risen to a huge commercial success.
Modern stereophonic systems include the well-known Dolby stereo, 5.1, 7.1 systems, the 22.2 system of the NHK \cite{hamasaki2005the, hamasaki2011the} or the currently state-of-the-art commercial spatial audio systems, the Dolby Atmos \cite{Atmos} and the DTS-X.
While the first three systems ensured 2D sound reproduction in the horizontal plane containing the listener's ears, recent systems introduced height information as well by adding height channels to the  reproduction layout.
%

Generally speaking---independently from the number of the speakers applied---stereophony generates the desired spatial impression by the recreation of the above localization cues at the listener position.
Correct localization therefore can be ensured only over a limited listening area, termed as the \emph{sweet spot}, however with increasing the number of the loudspeakers more realistic sound scenes can be created over a larger extent of space.
The source of the stereophonic signals may be either a recording of the sound scene to be reproduced, captured by a suitable microphone array \cite{lipshitz1985stereo, williams1999microphone, wittek2017development}, or the signal of the audio objects present in the virtual sound scene, distributed among the loudspeakers applied for reproduction.
The latter requires an appropriate \emph{panning law}, describing how the individual loudspeaker signals are obtained from the object source signal, ensuring that in the reproduced field the given object is perceived by the listener with the desired spatial characteristics (e.g. object position, apparent width, etc.) \cite{Pulkki2001a, Pulkki2001b}.
Traditional stereophonic panning techniques included applying intensity or time delay between the signals of the loudspeakers.
These techniques are commonly referred to as \emph{intensity stereophony} and \emph{time-based stereophony} respectively, both aiming to control the inter-aural time difference (ITD) between the listener's ears, hence setting the virtual audio object position in the sound scene.
Conventionally, intensity stereophony often applies the physically motivated \emph{sine law} \cite{Bauer1961, Rabenstein2007} and more lately the \emph{tangent law of panning}, \cite{Bennett1985, Rabenstein2007} in order to derive the required loudspeaker gains, while time-delay stereo relies mainly on experimental data \cite{lipshitz1985stereo, Hugonnet1997, Rumsey2001}.
Recently amplitude panning was extended towards 3D spatial audio by Vector Base Amplitude Panning (VBAP) introduced by Pulkki \cite{Pulkki1997}, allowing the positioning of phantom/virtual sources in the 3D space by distributing its excitation signal between loudspeaker triplets, opposed to the traditional pairwise stereophony panning laws\footnote{VBAP can be applied for loudspeaker pairs as well, in which case the formulation is equivalent with the tangent law of stereophony.}.

\paragraph{Ambisonics:}
As an alternative for stereophony the theory of Ambisonics was introduced by Gerzon in the 1970's, proposing both a novel recording and reproduction system \cite{gerzon1973periphony}.
Generally speaking Ambisonics represents a sound field in terms of its orthogonal decomposition over a sphere, so that the sound scene to be reproduced is described and stored as coefficients of the orthogonal basis functions.
The orthogonal basis for Ambisonics is given by the set of spherical harmonics.
The so-called encoding step of Ambisonics format is therefore the decomposition of the virtual sound field into a series of spherical harmonics up to a given order $N$, with the order defining the spatial resolution of the representation \cite{gerzon1985ambisonics}.
Traditional Ambisonics considered only spherical harmonics up to the first order ($N = 1$) \cite{gerzon1975the}, while modern microphone array designs allow the capturing of the sound field to be reproduced with a higher resolution with the technique termed as Higher Order Ambisonics (HOA, $N \geq 2$) \cite{5745011, 5744968, 5356221}.
Similarly to stereophony, besides measuring the target sound field at a predefined listener position, Ambisonics allows the rendering of virtual audio objects in the listening space:
once a model for the spatial characteristics of the virtual audio object is available, spherical harmonic decomposition may be performed analytically resulting in Ambisonics coefficients up to an arbitrary order \cite{4517624, Ahrens2010phd}.
Finally, at the reproduction, or decoding stage the loudspeaker signals for the actual loudspeaker layout are decoded from the spherical harmonics coefficients following some not defined decoding strategy \cite{Daniel2000:phd, Daniel2003b}.
Applying a decoding strategy that takes the actual reproduction loudspeaker characteristics into consideration is termed as Near Field Compensated Higher Order Ambisonics (NFC-HOA) \cite{Daniel2003}.

\paragraph{Sound field synthesis:}
An important property of spherical harmonic decomposition of a given sound field around a fixed point---practically around the listener's position---that increasing the decomposition order increases the area/volume at which the sound field is represented correctly.
It means that theoretically by increasing the Ambisonics order and the number of loudspeakers applied for reproduction, the physical properties of the desired virtual sound scene may be reproduced over an extended area, overcoming the sweet spot limitation of stereophony.
This fact adumbrates the motivation behind physically based sound field reproduction methods, commonly referred to as \emph{Sound Field Synthesis techniques}, or \emph{holophony} synthesizing the physical properties of a desired sound field over an extended listening area inherently ensures that the listener perceives the desired perceptual properties within the control region \cite{Spors2013:Survey}.
Obviously, controlling the sound field over an extended spatial region requires numerous loudspeakers, positioned on the boundary of the region under control.
Hence, these techniques are often referred to as \emph{massive multichannel sound reproduction methods} \cite{Spors2013:Survey, Zhang2017}.

Generally speaking, the sound field synthesis problem is an inverse problem: the synthesized sound field is available analytically in the form of an integral/summation of the individual loudspeakers' sound field, used for reproduction \cite{Ahrens2010phd, Ahrens2012, fazi2008surround, Fazi2010}.
In order to derive analytical loudspeaker signals this integral formulation has to be solved in an inverse manner for a any given desired virtual sound field.
The solution is available explicitly only in special geometries: for a spherical and circular arrangement of loudspeakers the direct solution is proven to coincide with NFC-HOA \cite{Daniel2003, fazi2008surround, Fazi2010, poletti2005three, 943347, Ahrens2008:Analytical_Circ_Spherical_SFS, Ahrens2011:icassp}, while for a theoretical infinite planar or linear distribution of loudspeakers the solution is known as the \emph{Spectral Division Method (SDM)} \cite{Ahrens2010a, Ahrens2012:Ambisonics_for_planar_linear, Ahrens2012}.
NFC-HOA and SDM are therefore commonly referred to as the \emph{explicit solution} for the sound field synthesis problem.

Besides NFC-HOA and SDM the most prominent, well-known sound field synthesis approach is Wave Field Synthesis, the main subject of the present dissertation.
Wave Field Synthesis (WFS) aims to recreate the desired sound field---or more precisely the desired wave fronts---by putting the Huygens-principle into practice: each reproduction loudspeaker acts as the source of a secondary wave front, so that the resultant wave front of the entire speaker arrangement coincides with that of a virtual sound source \cite{Berkhout1993:Acoustic_control_by_WFS, Verheijen1997:phd, Ahrens2012}.
In order to achieve this the spatial characteristic of the virtual sound scene, i.e. a spatial model has to be known, from which the required loudspeaker driving signals may be computed, similarly to NFC-HOA and SDM.
However, as an important difference WFS yields driving signal emerging from the local properties of the virtual sound field at the position of the actual loudspeaker, while the explicit solutions computes the driving signal for a given loudspeaker from a global description of the virtual field, given by the spherical harmonic components.
Hence, WFS is often termed as a \emph{local solution}, while NFC-HOA and SDM are \emph{global solutions}.
Furthermore, since WFS extracts the loudspeaker driving signals from an appropriate boundary integral representation of sound fields, containing the solution implicitly, WFS is referred to as an \emph{implicit solution}.

\paragraph{Categorization of spatial audio techniques:}
As a summary of the foregoing the above described spatial audio techniques may be categorized based on the representation of the virtual sound scene to be reproduced \cite{Spors2013:Survey}
\begin{itemize}
\item \emph{Channel-based representation} is the most widely used method up to nowadays, storing and transmitting directly the driving signals of the loudspeakers used for reproduction.
Traditional stereophonic methods like Dolby stereo, 5.1, 7.1 are commonly channel-based formats with the drawback of reproducing the desired spatial characteristics only by applying a predefined, often standardized loudspeaker layout.
\item \emph{Object-based representation} represents the desired virtual sound scene in terms of the virtual audio object properties, i.e. the time history of the individual auditory events to be reproduced along with their spatial characteristics (position, source width, etc.) as metadata.
Obviously, the decoding/reproduction stage requires the rendering of the loudspeaker driving signal for the actual loudspeaker layout, for which either VBAP, Wave Field Synthesis or simple stereophonic panning laws may be used.
\item As a third possibility, \emph{transform-based representation} stores the characteristics of the sound scene to be reproduced in terms of its coefficients for orthonormal spatial basis functions.
Similarly to the object-based case, a sophisticated decoding stage is required at the reproduction side in order to derive the driving signals for the loudspeaker geometry applied, for which either NFC-HOA or the Spectral Division Method may be applied.
\end{itemize}
Due to the simplicity of the required decoding stage, up to the recent years commercially available technologies almost exclusively utilized channel-based representations.
However, recently object-based reproduction techniques have started to gain more and more ground.
Dolby Atmos and DTS-X are the first commercially successful object-based surround sound technologies, both realizing object-based stereophony \cite{Atmos}.
Furthermore, the 3D audio coding part of the latest MPEG-H coding standard allows the standardized encoding and transmission and decoding of spatial audio scenes \cite{herre2015mpeg, 7056445}:
the standard audio decoder is capable of decoding either channel-based, object-based, or transform-based representation of the desired audio scene.
Object-based rendering is performed by Vector-based Amplitude Panning, while transform-based representation is realized by a standardized Higher-Order Ambisonics encoder and decoder.

Also, commercially available Wave Field Synthesis based sound systems are available commercially in the recent years with the introduction of the IOSONO and Sonic Emotion systems,
even though that no complete unified WFS theory has existed so far:
existing WFS theory deals with the reproduction of specific sound object models applying specific loudspeaker geometries with well-defined control regions.
These limitations are overcome in the present thesis by presenting a generalized Wave Field Synthesis approach.
In the followings, first a brief overview on Wave Field Synthesis history is given, highlighting the deficiencies of its theory that motivated the research, summarized in the present dissertation.

\section{Wave Field Synthesis history and motivation of the presented research:}

Huygens' principle states that each point on a wavefront at a given time instant acts as the source of spherical wavelets and the sum of these secondary waves determine the form of the original wavefront at any subsequent time \cite{Huygens1690}.
The idea of synthesizing wave fronts with loudspeakers based on the Huygens principle in order to reconstruct wave fields over an extended listening area dates back to the 1930's, to the concept of the \emph{acoustic curtain} by Steinberg and Snow \cite{Steinberg1934}.
They intuitively stated that an auditory scene could be recorded, transmitted and reproduced by recording the scene with a large, densely spaced microphone array and reproducing with the same amount of loudspeakers located in the same geometry at the reproduction venue.
Due to the obvious technical constraints the concept has not been put into practical application until the 1980's.

The original theory of Wave Field Synthesis---often referred to as \emph{traditional WFS}---evolved from the works of Berkhout et al. at the Technical University of Delft by applying results, well-known in the field of seismic migration applied for sound field control.
The basis of WFS formulation were the Rayleigh integrals, the mathematical form of the Huygens' principle representing a sound field as the sum of spherical waves emerging from an infinite plane.
Berkhout applied the stationary phase method (SPA) to the Rayleigh integrals in order to arrive at loudspeaker driving signals for a linear array of secondary loudspeakers instead of the infeasible planar array.
The original formulation provided driving signals for loudspeakers with dipole characteristics \cite{Berkhout1988, Berkhout1993:Acoustic_control_by_WFS}---soon extended for monopole loudspeakers as well \cite{doi:10.1121/1.404755, Vogel1993:phd, devries1994the, Start1997:phd, Verheijen1997:phd, Bruijn2004}---, reproducing the wave front of a virtual spherical wave in the horizontal plane containing the loudspeaker array.
It was realized that the dimensionality reduction performed by the SPA restricts the amplitude correct restriction to a control curve in the plane of synthesis, termed here as the reference curve \cite{sonke1998variable}.
For traditional WFS this reference curve was chosen to be a reference line, parallel with the loudspeaker arrangement.
The theoretical framework of traditional WFS has been extended towards various aspects, including the consideration of loudspeaker directivity \cite{devries1996sound, Firtha2012:isma}, stochastic loudspeaker properties \cite{Firtha2013:daga, Firtha2013:internoise}, application of curved arrays \cite{start1996application} (without taking the reference curve modifications into consideration), synthesis of extended and directive sources \cite{Corteel2007, Baalman2008:phd}, the perceptual aspects of synthesis \cite{Wittek2007:phd, Corteel2006:phd, Hulsebos2004:phd, wittek2004spatial, strauss2004generation} or the inclusion of the reproduction room to the general theory \cite{spors2003an, corteel2003listening, 1326755, buchner2004efficient, petrausch2005simulation}.
Traditional WFS was also the subject of various research projects, most notably the CARROUSO project, aiming at the integration of the technique into the MPEG-4 standard \cite{sporer2001carrouso}. 
This endeavor was not realized eventually, but the two "spin-off" companies of the project, the IOSONO and Sonic Emotion are still offering commercially available WFS systems nowadays.

The latest milestone in Wave Field Synthesis theory was the works of Spors et al., who generalized WFS towards the synthesis of an arbitrary analytically available sound field applying an arbitrary shaped loudspeaker contour \cite{Spors2008:WFSrevisited, Rabenstein2007}.
The presented loudspeaker driving signals allowed the synthesis of general 2-dimensional sound field, ensuring amplitude correct synthesis at a single reference point,
hence allowing the reproduction of complex virtual sound scene, e.g. the field, generated by a moving sound source \cite{Ahrens2008moving, Ahrens2008moving_b}.
The method however---since it derived driving signals from the 2D Rayleigh integral---failed to control the amplitude of general 3D sound fields.
Furthermore, the exact connection between traditional and the latter revisited WFS formulations has not been known so far.

\vspace{3mm}
The present dissertation revisits the theoretical basics of Wave Field Synthesis.
First, several high frequency acoustic concepts are introduced---e.g the local wavenumber vector and the local wavefront curvature---being beneficial for the deeper understanding of the results, concerning Wave Field Synthesis.
By using these concepts brief and physically illustrative loudspeakers driving functions are derived for WFS.
These driving functions allow the reproduction of arbitrary two, or three-dimensional sound fields applying an arbitrary shaped ensemble of loudspeakers with the amplitude of the synthesized field optimized along an arbitrary reference curve.
Hence, the presented theoretical framework includes previous WFS approaches as special cases.

The introduced concepts are well-known in the field of high frequency acoustics and ray acoustics.
This indicates the important fact that WFS can be regarded as the ray tracing, or ray-based solution of the general sound field synthesis problem---which is a key message of the present work---, realizing the matching of the wavefronts of the virtual source and the secondary loudspeakers' at the predefined reference positions \footnote{It should be noted that in some of the early works of Berkhout termed the technique as Wave Front Synthesis \cite{berkhout1992wave, doi:10.1121/1.404755} which terminology may be more expressive, reflecting the physical interpretation of its operation.}.
This fact is also confirmed in the present thesis by showing that WFS is the high frequency, ray based approximations to the explicit, direct solution for the sound field synthesis problem.
This connection of WFS techniques and the explicit SFS solution has been investigated only for particular virtual source models in the related literature, e.g. for the case of a virtual spherical wave \cite{Spors2010:analysis_and_improvement} and for a virtual plane wave \cite{Schultz2016:DAGA}.

Finally, as a complex application example for the presented framework the reproduction of a moving virtual source is investigated in details.
The reproduction of moving sources has been the subject of studies since the early age of WFS theory, emerging as an obvious claim when dynamic sound scenes are to be synthesized.
Early formulations attempted to synthesize the field of a moving point source by applying the traditional WFS driving signals with changing the virtual source position as the function of time.
This approach however failed to properly recreate Doppler effect, leading to serious artifacts in the synthesized field as investigated in details by Franck et al. \cite{Franck2007}.
Ahrens et al. used the revisited WFS formulation in order to recreate the field of a moving source \cite{Ahrens2008moving, Ahrens2008moving_b, Ahrens2012}.
However, due to physical constrains of revisited WFS theory, it failed to control the amplitude of the synthesized source.
In the present work the physically correct loudspeaker driving signals are presented for the synthesis of moving sources of sound, applying either WFS or  the explicit solution, termed the Spectral Division Method.

With highlighting the related publications by the author forming the basis of the present work, the thesis is structured as follows
\begin{itemize}
\item Chapter \ref{sec:general_wave_theory} gives an overview on basic acoustic concepts, required for dealing with the general sound field synthesis problem.
Different descriptions of sound fields are discussed, including spectral integral and boundary integral representations.
%
\item Chapter \ref{sec:high_freq_approx} introduces important high frequency concepts---the local wavenumber  vector local wavefront curvature and the high frequency gradient approximation---which are later applied in order to explain results, concerning the \emph{stationary phase approximation (SPA)} of integrals.
The SPA is of central importance in the aspect of the present thesis: loosely speaking the present work discusses how integral representations can be manipulated by the SPA in order to extract the desired SFS driving signals from them.
The application of the SPA to the different integral representations are discussed via examples.
Some of these results in these examples---describing the wave dynamics by investigating the sound field's phase function and its derivatives---are not unknown in the field of ray acoustics, however the present thesis introduces a novel approach for their derivation, so far unknown in the related literature.
%
\item Chapter \ref{sec:sound_field_synthesis} deals with the solution of the general sound field synthesis problem.
By applying the SPA to the appropriate 3D boundary integral representation a unified Wave Field Synthesis framework is introduced, capable of the synthtesis of an arbitrary sound field applying arbitrary shaped loudspeaker ensembles, with optimizing the synthesis on a pre-defined reference curve \cite{Firtha2016, schultz2017wave}.
The application of the presented concepts are illustrated with examples, highlighting how previous WFS approaches are included inherently in the present framework.
By applying asymptotic approximations to the Spectral Division Method a novel SFS method is introduced, ensuring wavefront matching along a control curve requiring merely the virtual field measured at these control points \cite{Firtha2017:daga}.
Finally, it is highlighted, that the proposed method is equivalent with WFS, hence indicated the general relation between the implicit and explicit methods \cite{Firtha2018:WFS_vs_SDM}.
As an example for the latter results the effects and possibilities for the compensation of directive loudspeakers are discussed \cite{Firtha2018_daga_a}.
%
\item As a detailed, complex examples for the theoretical results in Chapter \ref{sec:moving_source_synthesis} the reproduction of moving virtual sources is elaborated.
By adapting the unified WFS theory to the analytical description of sources under motion driving signals are presented for an arbitrary contour of loudspeakers \cite{Firtha2015:daga, firtha2016wave, doi:10.1121/1.4996126}.
Besides Wave Field synthesis, the explicit SFS solution for moving sources are also presented analytically, serving as a reference solution \cite{Firtha2014:daga, Firtha2014:isma}.
Finally, several practical aspects of synthesis are discussed, evolving at the practical application of the presented driving functions, e.g. numerical calculation of the presented analytical driving functions and the effects of the applied loudspeaker geometry \cite{Firtha2018_daga_a}.
For this latter question the explicit solution---for which WFS constitutes a high-frequency approximation similarly to the case of stationary sound scenes \cite{firtha2015sound}---is utilized, allowing the analytical investigation of the involved secondary artifacts \cite{firtha2016:daga}.
\end{itemize}
