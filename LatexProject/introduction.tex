\section{Overview of spatial audio techniques}
\emph{Spatial audio} aims at the recreation of a sound scene containing sources of sound, termed as audio objects, in a sense that the human listener perceives the spatial characteristics of the desired acoustic environment \cite{Zhang2017}.
\emph{Sound field reproduction} achieves this by driving an arrangement of fix positioned loudspeakers, so that the superposition of the sound waves emerging from the individual loudspeakers generates the impression of the desired virtual audio object, present in the sound scene.
Alternatively, \emph{binaural rendering} applies a headphone for the reproduction of localization cues for the human auditory system directly at the ears of the listener.
These cues are triggered by the head-related transfer function (HRTF) including the interaural time and level differences (ITD and ILD) due the anthropometry of the listener, dynamic cues due to the movement of the listener's head and several environment scattering cues, which all are combined by the human brain, generating the perceived spatial impression \cite{Blauert1983}.

The present thesis considers only spatial audio by loudspeakers.
In this case, the general aim is the derivation of loudspeaker driving signals from a given source excitation signal in a manner that the reproduced field exhibits prescribed spatial characteristics, e.g. a specific apparent direction of arrival or a prescribed apparent source width.
In the following, first a short overview is given on the different sound field reproduction approaches, classified based on the basic goal of reproduction.

\paragraph{Stereophony:}
Sound field reproduction has been the subject of excessive study and development over the second half of the XX. century, starting with the work of Blumlein, who introduced the first two-loudspeaker system in 1931 (along with the related recording, transmission and playback methodology) and thereby creating the basics of \emph{stereophony} \cite{Blumlein1932, Alexander2000}.
Blumlein's invention was first put to practice in the 1950s, and since then stereophony has risen to a huge commercial success.
Modern stereophonic systems include the well-known Dolby stereo, 5.1, 7.1 systems, the 22.2 system of the NHK \cite{hamasaki2005the, hamasaki2011the} or the current state-of-the-art commercial spatial audio systems, Dolby Atmos \cite{Atmos} and DTS-X.
While the first three systems ensured only 2D sound reproduction in the horizontal plane containing the listener's ears, recent systems introduced height information as well, by adding height channels to the reproduction loudspeaker layout.

Generally speaking---independently from the number of the speakers applied---stereophony generates the desired spatial impression by the recreation of some of the above localization cues at the listener position.
%Although several stereo rendering techniques rely on physical basics, still stereophony aims at the perceptual recreation of sound fields.
Correct localization therefore can be ensured only over a limited listening area termed as the \emph{sweet spot}, being a central limitation of these techniques.
Increasing the number of the loudspeakers allows only for a more precise reproduction of the target fields' spatial attributes (e.g. for a more accurate localization).

The source of the stereophonic signals may be either a recording of the sound scene to be reproduced, captured by a suitable microphone array \cite{lipshitz1985stereo, williams1999microphone, wittek2017development} or the signal of the audio objects present in the virtual sound scene, distributed among the loudspeakers applied for reproduction.

The latter approach requires an appropriate \emph{panning law}, describing how the individual loudspeaker signals are obtained from the object source signal, ensuring that in the reproduced field the given audio object is perceived by the listener with desired spatial characteristics (e.g. object position, apparent width, etc.) \cite{Pulkki2001a, Pulkki2001b}.
Traditional stereophonic panning techniques included applying either interchannel intensity difference or time delay between the signals of the loudspeakers.
These techniques are commonly referred to as \emph{intensity stereophony}/\emph{amplitude panning} and \emph{time-based stereophony} respectively.
Ultimately both approaches control the apparent virtual audio object's position by adjusting the interaural time difference between the listener's ears (meaning that even amplitude difference between the loudspeaker signals is converted to time difference at the ears, as it is discussed in Section \ref{Sec:stereophony}).

\begin{figure}  
\small
 	\begin{minipage}[c]{0.5\textwidth} 
 	\hspace{0.7cm}
	\begin{overpic}[width = 0.75\columnwidth ]{Figures/Introduction/stereo_a.png}
	\small
	\put(-10,-10){(a)}
	\put(40.5,40.5){$\phi_p$}
	\put(50,29){$\phi_0$}
	\put(19,100){\parbox{.65in}{phantom source}}
	\put(45,0){listener at sweet spot}	
	\begin{turn}{90}
 	\put(50,-52){stereo axis}
	\end{turn} 
	\end{overpic}   
 	\end{minipage}
    \begin{minipage}[c]{0.5\textwidth}
	\begin{overpic}[width = 1\columnwidth ]{Figures/Introduction/stereo_b.png} 
	\small
	\put(0,0){(b)}\end{overpic}   
	\end{minipage}
    \caption{Typical two-channel stereophonic loudspeaker geometry (a) and exemplary interchannel amplitude and time differences (b) for the panning of the phantom source to be localized from the angular direction $\phi_p$.
    Most of the data are experimental results, as published by de Boer \cite{deBoer1940} (measured for male speech signal), Brittain and Leakey (measured for speech signal, limited to $5~\mathrm{kHz}$) \cite{Leakey1956} and Leakey \cite{Leakey1960} (measured for wide-band speech signal), while the tangent law is an analytically given curve, based on a simple physical model.}
\label{fig:introduction:stereo}
\end{figure}

Originally, both the interchannel amplitude and time differences---required in order to ensure the desired spatial impression---were defined based on experimental data \cite{deBoer1940, Leakey1956, lipshitz1985stereo, Hugonnet1997, Rumsey2001}.	
Later, the physically motivated \emph{sine law} \cite{Bauer1961, Rabenstein2007} and the \emph{tangent law of panning}\cite{Bennett1985, Rabenstein2007} were introduced, based on an analytical model of the reproduced stereophonic field.
The latter is discussed within the context of the introduced theoretical framework in the present thesis.
Several basic intensity and time-based panning laws are depicted in Figure \ref{fig:introduction:stereo} (b).
Amplitude panning was extended towards 3D spatial audio by \emph{Vector Base Amplitude Panning (VBAP)} introduced by Pulkki \cite{Pulkki1997}, allowing the positioning of phantom/virtual sources in the 3D space by distributing its excitation signal between loudspeaker triplets.\footnote{VBAP can be applied for loudspeaker pairs as well, in which case the formulation is equivalent with the tangent law of stereophony.}

\paragraph{Ambisonics:}
As an alternative for stereophony, the theory of \emph{Ambisonics} was introduced by Gerzon in the 1970s, proposing both a novel recording and reproduction system \cite{gerzon1973periphony} and later elaborating an objective evaluation methodology for Ambisonic type sound systems \cite{gerzon1992general}.
Being an intermediate approach between stereophony and sound field synthesis, traditional Ambisonics aims at the reproduction of physical properties of a sound field in the proximity of a fixed listening position.

Generally speaking, Ambisonics represents a sound field in terms of its orthogonal decomposition over a sphere, so that the sound scene to be reproduced is described and stored as coefficients of the orthogonal basis functions.
The orthogonal basis for Ambisonics is given by the set of \emph{spherical harmonics}.
The so-called encoding step of Ambisonics format is therefore the decomposition of the sound field to be reproduced into a series of spherical harmonics up to a given order $N$, with the order defining the spatial resolution and the size of the receiver zone for the representation \cite{gerzon1985ambisonics}.
Ambisonics signals hence are time histories belonging to given spherical harmonic shapes.

Traditional Ambisonics considered only spherical harmonics up to the first order ($N = 1$) \cite{gerzon1975the}, while modern microphone array designs allow the capturing of the sound field to be reproduced at a higher resolution with the technique termed as \emph{Higher Order Ambisonics} (HOA, $N \geq 2$) \cite{5745011, 5744968, 5356221}.
Similarly to stereophony, besides measuring the target sound field at a predefined listener position, Ambisonics allows the rendering of virtual audio objects defined by a physical model:
once a model for the spatial characteristics of the virtual audio object is available, spherical harmonic decomposition may be performed analytically resulting in Ambisonics coefficients up to an arbitrary order \cite{4517624, Ahrens2010phd}.

Finally, at the reproduction, or decoding stage the loudspeaker signals for the actual loudspeaker layout are decoded from the spherical harmonics coefficients following some suitable decoding strategy \cite{Daniel2000:phd, Daniel2003b, zotter:hal-01106738, zotter2012all, zotter2018ambisonic}.
Applying a decoding strategy that takes the actual reproduction loudspeaker characteristics into consideration is termed as \emph{Near-Field Compensated Higher Order Ambisonics (NFC-HOA)} \cite{Daniel2003}.

\paragraph{Sound field synthesis:}
An important property of spherical harmonic decomposition of a given sound field around a fixed point is that increasing the decomposition order increases the area/volume at which the sound field is represented correctly.
By driving a loudspeaker ensemble that is capable of reproducing higher order harmonics the sweet spot limitation of stereophony could be overcome.
This fact adumbrates the motivation behind physically based sound field reproduction methods, commonly referred to as \emph{sound field synthesis techniques} or \emph{holophony}: once the physical properties of a desired sound field are reproduced over an extended listening area, it is inherently ensured that the listener perceives the desired perceptual properties \cite{Spors2013:Survey}.
Obviously, controlling the sound field over an extended region requires numerous loudspeakers, positioned on the boundary of the control region, as depicted in Figure \ref{fig:introduction:sfs_aim}.
Hence, these techniques are often referred to as \emph{massive multichannel sound reproduction methods} \cite{Spors2013:Survey, Zhang2017}.

\begin{figure}  
\small
  \begin{minipage}[c]{0.64\textwidth}
	\begin{overpic}[width = 1\columnwidth ]{Figures/Introduction/sfs_aim.png}
	\small
	\put(60,30){listening region}
	\put(0,45){\parbox{.5in}{virtual audio object}}
	\put(45,7){loudspeaker array}
	\end{overpic}   \end{minipage}\hfill
	\begin{minipage}[c]{0.3\textwidth}
    \caption{The general geometry for sound field synthesis: the goal of synthesis is to reproduce the physical properties of a virtual sound object, or primary source of sound inside a control region, bounded by a densely spaced loudspeaker ensemble.}
\label{fig:introduction:sfs_aim}  \end{minipage}
\end{figure}

Generally speaking, the sound field synthesis problem is an inverse problem: the synthesized sound field is described analytically in the form of an integral/summation of the individual loudspeakers' sound field \cite{fazi2008surround, Fazi2010, Ahrens2010phd, Ahrens2012}.
In order to derive analytical loudspeaker signals, this integral formulation has to be solved in an inverse manner for any target virtual sound field.
The solution is available explicitly only for special geometries: for a spherical and circular arrangement of loudspeakers the direct solution is proven to coincide with NFC-HOA \cite{943347, Daniel2003, poletti2005three, fazi2008surround, Ahrens2008:Analytical_Circ_Spherical_SFS, Fazi2010, Ahrens2011:icassp}, while for a theoretical infinite planar or linear distribution of loudspeakers the solution is known as the \emph{Spectral Division Method (SDM)} \cite{Fazi2010, Ahrens2010a, Ahrens2012:Ambisonics_for_planar_linear, Ahrens2012}.
NFC-HOA and SDM are therefore commonly referred to as the \emph{explicit solutions} for the sound field synthesis problem.

Besides NFC-HOA and SDM the most prominent, well-known sound field synthesis approach is Wave Field Synthesis, being the main subject of the present dissertation.
Wave Field Synthesis (WFS) aims to recreate the desired sound field---or more precisely the desired wavefront---by putting the Huygens principle into practice: 
each reproduction loudspeaker acts as the source of a secondary wavefront, so that the resultant field of the entire speaker arrangement coincides with that of a virtual sound source \cite{Berkhout1993:Acoustic_control_by_WFS, Verheijen1997:phd, Ahrens2012}.
As WFS yields driving signals from the local behavior of the virtual sound field at the position of the loudspeakers it is often termed as a \emph{local solution} to the SFS problem.
On the other hand, the explicit solutions compute the driving signal for a single loudspeaker from the global description of the virtual field, therefore NFC-HOA and SDM are termed as \emph{global solutions}.
Furthermore, since WFS extracts the loudspeaker driving signals from an appropriate boundary integral representation of sound fields containing the solution implicitly, WFS is referred to as an \emph{implicit solution}.

\paragraph{Categorization of spatial audio techniques:}
As a summary of the foregoing the above described spatial audio techniques may be categorized based on the representation of the virtual sound scene to be reproduced \cite{Spors2013:Survey}
\begin{itemize}
\item \emph{Channel-based representation} is the most widely used method up to nowadays, storing and transmitting directly the driving signals of the loudspeakers, used for reproduction.
Traditional stereophonic methods, like Dolby stereo, 5.1 and 7.1, are commonly channel-based formats with the drawback of reproducing the desired spatial characteristics only by applying a predefined, often standardized loudspeaker layout.
%
\item \emph{Object-based representation} stores the desired virtual sound scene in terms of the virtual audio object properties: the time history of the individual auditory events along with their spatial characteristics as metadata (position, source width, etc.).
Obviously, the decoding/reproduction stage requires the rendering of the loudspeaker driving signal for the actual loudspeaker layout, for which either VBAP, Wave Field Synthesis or simple stereophonic panning laws may be used.
%
\item As a third possibility, \emph{transform-based representation} stores the characteristics of the sound scene in terms of its coefficients for the expansion into  orthonormal spatial basis functions.
Similarly to the object-based case, a sophisticated decoding/rendering stage is required at the reproduction side in order to derive the driving signals for the loudspeaker arrangement, for which either NFC-HOA or the Spectral Division Method may be applied.
\end{itemize}

Due to the simplicity of the reproduction stage, up to the recent years commercially available technologies almost exclusively utilized channel-based representations,
however, in the recent years object-based reproduction techniques have started to gain more ground.
Dolby Atmos and DTS-X are the first commercially successful object-based surround sound technologies, both realizing object-based stereophony \cite{Atmos}.
As a further step, the 3D audio coding part of the latest MPEG-H coding standard allows for standardized encoding, transmission and decoding of spatial audio scenes \cite{herre2015mpeg, 7056445}:
the standard audio decoder is capable of decoding either channel-based, object-based, or transform-based representations of the desired audio scene.
Object-based rendering is performed by Vector-based Amplitude Panning, while transform-based representation is realized by a standardized Higher-Order Ambisonics encoder and decoder.

Since several years Wave Field Synthesis based sound systems has been available commercially since the introduction of the IOSONO and Sonic Emotion systems, even though that no complete, generalized WFS theory has existed so far:
Previous WFS approaches have been dealing with the reproduction of specific sound object models applying specific loudspeaker geometries with restricted control regions.
These limitations are overcome in the present thesis by presenting a generalized Wave Field Synthesis approach.
In the following, first a brief overview of Wave Field Synthesis history is given, with highlighting the deficiencies of its theory that motivated the research, summarized in the present dissertation.

\section{Wave Field Synthesis history and motivation of the presented research:}
\begin{figure}
	\small
	\centering
	\begin{overpic}[width = .7\columnwidth]{Figures/Introduction/huygens_wfs.png}
	\put(31,3){primary wavefront}
	\put(14,45){\parbox{.5in}{secondary wavefronts}}
	\put(60,30){listening region}
	\end{overpic}
	\caption{Reproduction of a primary wavefront based on the Huygens principle.}
	\label{Fig:intro:huygens_wfs}
\end{figure}

The Huygens principle states that each point on a primary wavefront at a given time instant acts as the source of spherical wavelets, and the sum of these secondary waves determine the form of the original wavefront at any subsequent time \cite{Huygens1690}.
Hence, if secondary sources of sound are present in the space covering a part of the primary wavefront, then the primary field can be reconstructed as the sum of the secondary wavefronts.
The idea of synthesizing wavefronts with loudspeakers based on the Huygens principle in order to reconstruct wavefields over an extended listening area dates back to the 1930s, to the concept of the \emph{acoustic curtain} by Steinberg and Snow \cite{Steinberg1934}.
They intuitively stated that an auditory scene could be recorded, transmitted and reproduced by recording the sound scene with a large, densely spaced microphone array and playing back with the same amount of loudspeakers located in the same arrangement as the microphones, at the reproduction venue.\footnote{In fact, Snow termed the acoustic curtain concept as an ideal stereophonic system \cite{7254953}.}
The concept is illustrated in Figure \ref{Fig:intro:huygens_wfs}.
Due to the obvious technical constraints of that time, the concept has not been put into practical application until the 1980s.

The original theory of Wave Field Synthesis---often referred to as \emph{traditional WFS}---evolved from the works of Berkhout et al. at the Technical University of Delft utilizing concepts, well-known in the field of seismic migration.%, applied for sound field control.
The basis of WFS theory were the Rayleigh integrals, the mathematical form of the Huygens principle, representing a sound field as the sum of spherical waves, emerging from an infinite plane.
Berkhout applied the stationary phase method (SPA) to the Rayleigh integrals in order to arrive at loudspeaker driving signals for a linear array of loudspeakers instead of the practically infeasible planar array.
The original formulation provided driving signals for loudspeakers with dipole characteristics \cite{Berkhout1988, Berkhout1993:Acoustic_control_by_WFS}---soon extended for monopole loudspeakers as well \cite{doi:10.1121/1.404755, Vogel1993:phd, devries1994the, Start1997:phd, Verheijen1997:phd, deBrujin2004}---reproducing the wavefront of a virtual spherical wave in the horizontal plane, containing the loudspeaker array.
It was discussed that the dimensionality reduction performed by the SPA restricts the amplitude correct reproduction to a control curve in the plane of synthesis, termed here as the reference curve \cite{sonke1998variable}.
For traditional WFS, this reference curve was usually chosen to be a reference line, parallel with the loudspeaker arrangement \cite{start1996application, Start1997:phd}.
The theoretical framework of traditional WFS has been extended towards various aspects, including the consideration of loudspeaker directivity \cite{devries1996sound, Firtha2012:isma}, application of curved arrays \cite{start1996application}, synthesis of extended and directive sources \cite{Corteel2007, Baalman2008:phd}, the perceptual aspects of synthesis \cite{Hulsebos2004:phd, wittek2004spatial, strauss2004generation, Corteel2006:phd, Wittek2007:phd}, stochastic loudspeaker and array properties \cite{Firtha2013:daga, Firtha2013:internoise}, or the inclusion of the reproduction room's effects to the WFS theory \cite{spors2003an, corteel2003listening, 1326755, buchner2004efficient, petrausch2005simulation}.
Traditional WFS was also the subject of various research projects, most notably the CARROUSO project, aiming at the integration of the technique into the MPEG-4 standard \cite{sporer2001carrouso}. 
This endeavor was not realized eventually, but two "spin-off" companies of the project, the IOSONO and Sonic Emotion are still offering commercially available WFS systems nowadays.

The latest milestone in Wave Field Synthesis theory were the works of Spors et al., generalizing WFS towards the synthesis of an arbitrary analytically available sound field, applying an arbitrary shaped loudspeaker contour \cite{Rabenstein2007, Spors2008:WFSrevisited}.
The presented loudspeaker driving signals allowed the synthesis of general two-dimensional sound fields, ensuring amplitude correct synthesis at a single reference point,
allowing the reproduction of complex virtual sound scenes, e.g. the field, generated by a moving sound source \cite{Ahrens2008moving, Ahrens2008moving_b, Ahrens2011_moving_source_WFS}.
However, the method---since it derived driving signals from the 2D Rayleigh integral---failed to control the amplitude of general 3D sound fields.
Furthermore, the exact connection between traditional and the latter \emph{revisited WFS} formulations has not been known so far.

\vspace{3mm}
The present dissertation revisits the theoretical basics of Wave Field Synthesis.
First, several high frequency acoustic concepts are introduced---e.g the local wavenumber vector and the local wavefront curvature---being beneficial for the deeper understanding of the results, concerning WFS.
By using these concepts brief and physically illustrative loudspeakers driving signals are derived.
These driving signals allow the reproduction of arbitrary two-, or three-dimensional sound fields applying an arbitrary shaped ensemble of loudspeakers with the amplitude of the synthesized field optimized along an arbitrary reference curve.
Hence, the presented theoretical framework includes previous WFS approaches as special cases.

The introduced high frequency concepts are well-known in the field of high frequency acoustics and ray acoustics.
This indicates the important fact that WFS can be regarded as the ray tracing, or ray-based solution of the general sound field synthesis problem---which is a key message of the present work---realizing the matching of the virtual source's and the secondary loudspeakers' wavefronts at the predefined reference positions.\footnote{It should be noted that in some of the early works of Berkhout termed the technique as Wave Front Synthesis \cite{berkhout1992wave, doi:10.1121/1.404755} which terminology may be more expressive, reflecting the underlying physical interpretation of the approach.}
This fact is also confirmed in the present thesis by showing that WFS is the high frequency, ray-based approximation of the explicit, direct solution for the sound field synthesis problem.
This connection of WFS and the explicit solution has been investigated only for particular virtual source models in the related literature, e.g. for the case of a virtual spherical wave \cite{Spors2010:analysis_and_improvement} and for a virtual plane wave \cite{Schultz2016:DAGA}.

Finally, as a complex application example for the presented framework, the reproduction of moving virtual sources is investigated in details.
The reproduction of moving sources has been the subject of studies since the early age of WFS theory, as an obvious need when dynamic sound scenes are to be synthesized.
Early formulations attempted to synthesize the field of a moving point source by applying the traditional WFS driving signals with changing the virtual source position as the function of time.
This approach, however, failed to properly recreate the Doppler effect, leading to serious artifacts in the synthesized field as investigated in details by Franck et al. \cite{Franck2007}.
Ahrens et al. used the revisited WFS formulation in order to recreate the field of a moving source \cite{Ahrens2008moving, Ahrens2008moving_b, gasparini2011real, Ahrens2012}.
However, due to the physical constraints of revisited WFS theory, it failed to control the amplitude of the synthesized source.
In the present work, the physically correct loudspeaker driving signals are presented for the synthesis of moving sources of sound, applying either WFS or the explicit solution.

With highlighting the related publications by the author, the thesis is structured as follows
\begin{itemize}
\item Chapter \ref{sec:general_wave_theory} gives an overview of basic acoustic concepts, required for dealing with the general sound field synthesis problem.
Different descriptions of sound fields are discussed, including spectral integral and boundary integral representations.
%
\item Chapter \ref{sec:high_freq_approx} introduces important high frequency concepts---the local wavenumber vector, the local wavefront curvature and the high frequency gradient approximation---which are later applied in order to explain results concerning the \emph{stationary phase approximation (SPA)} of integrals.
The SPA is of central importance in the aspect of the present thesis: loosely speaking, the present work discusses how integral representations can be manipulated by the SPA in order to extract the desired SFS driving signals from them.
The application of the SPA to the different integral representations is discussed via examples.
Some of the results in these examples---describing wave dynamics by investigating the sound field's phase function and its derivatives---are well-known in the field of ray acoustics, however, the present thesis introduces a novel approach for their derivation, so far unknown in the related literature.
%
\item Chapter \ref{sec:sound_field_synthesis} deals with the solution of the general sound field synthesis problem.
By applying the SPA to the boundary integral representation of wavefields a generalized Wave Field Synthesis framework is introduced, capable of the synthesis of an arbitrary sound field applying arbitrary shaped loudspeaker ensembles, with optimizing the synthesis on a pre-defined reference curve \cite{Firtha2016, schultz2017wave}.
Several applications of the presented concepts are illustrated with examples, highlighting how previous WFS approaches are included inherently in the present framework.
By applying an asymptotic approximation to the Spectral Division Method a novel SFS method is introduced, ensuring wavefront matching along a control curve requiring merely the virtual field measured at these control points \cite{Firtha2017:daga}.
It is highlighted that the proposed method is equivalent with WFS, indicating the general relation between the implicit and the explicit SFS methods \cite{Firtha2018:WFS_vs_SDM, Schultz2019:HOA_vs_WFS}.
Finally, the effect of the discrete secondary source distribution (instead of the theoretical continuous one) is discussed, and a novel anti-aliasing strategy is introduced \cite{Firtha2018_daga_a, 8611109}.
%
\item As a detailed, complex example for the above theoretical results, in Chapter \ref{sec:moving_source_synthesis} the reproduction of moving virtual sources is investigated \cite{Firtha2019:daga}.
By adapting the generalized WFS theory to the analytical description of sources under motion, driving signals are presented for an arbitrary contour of loudspeakers \cite{Firtha2015:daga, firtha2016wave, doi:10.1121/1.4996126}.
Besides Wave Field Synthesis, the explicit solution is also presented, serving as a reference solution \cite{Firtha2014:daga, Firtha2014:isma}.
Finally, several practical aspects of synthesis are discussed, evolving at the practical application of the presented driving signals, e.g. numerical calculation of the presented analytical driving signals and the effects of the applied loudspeaker array shape \cite{Firtha2018_daga_moving_source}.
For this latter question the explicit solution---for which WFS constitutes a high frequency approximation similarly to the case of stationary sound scenes \cite{firtha2015sound}---is utilized to the analytical investigation of the evolving artifacts \cite{firtha2016:daga}.
\end{itemize}