\section{Overview of spatial audio techniques}
Spatial audio aims at the recreation of a sound scene, in a sense that the human listener perceives the spatial characteristics of the desired acoustic environment \cite{Zhang2017}.
\emph{Sound field reproduction} achieves this by driving an arrangement of fix positioned loudspeakers, so that the sum of the sound waves emerging from the individual loudspeakers generate the impression of the desired virtual audio object, present in the sound scene.
Alternatively \emph{binaural rendering} applies a headphone for the reproduction of localization cues for the human auditory system directly at the ears of the listener.
These cues include the interaural time and level differences (ITD and ILD), the head-related transfer function (HRTF) due the anthropometry of the listener, dynamic cues due to the movement of the listener's head and several environment scattering cues, which all are combined by the human brain, generating the perceived spatial impression \cite{Blauert1983}.

The present thesis considers only spatial audio by loudspeakers.
In the followings first a short overview is given on the different sound field reproduction approaches, classified according to the basic goal of reproduction.

\paragraph{Stereophony:}
Sound field reproduction has been the subject of excessive study and development over the second half of the XX. century, starting with the work of Blumlein, who introduced the first two-loudspeaker system in 1931 (along with the related recording, transmission and playback methodology) and thereby creating the basics of \emph{stereophony} \cite{Blumlein1932, Alexander2000}.
Blumlein's invention was first put to practice in the 1950's, and since then stereophony has risen to a huge commercial success.
Modern stereophonic systems include the well-known Dolby stereo, 5.1, 7.1 systems, the 22.2 system of the NHK \cite{hamasaki2005the, hamasaki2011the} or the currently state-of-the-art commercial spatial audio systems, the Dolby Atmos \cite{Atmos} and the DTS-X.
While the first three systems ensured only 2D sound reproduction in the horizontal plane containing the listener's ears, recent systems introduced height information as well by adding height channels to the reproduction loudspeaker layout.

Generally speaking---independently from the number of the speakers applied---stereophony generates the desired spatial impression by the recreation of some of the above localization cues at the listener position.
%Although several stereo rendering techniques rely on physical basics, still stereophony aims at the perceptual recreation of sound fields.
Correct localization therefore can be ensured only over a limited listening area, termed as the \emph{sweet spot}, being a central limitation of these techniques.
Increasing the number of the loudspeakers allows only for a more precise reproduction of the target fields's spatial attributes (e.g. for a more accurate localization).

The source of the stereophonic signals may be either a recording of the sound scene to be reproduced, captured by a suitable microphone array \cite{lipshitz1985stereo, williams1999microphone, wittek2017development}, or the signal of the audio objects present in the virtual sound scene, distributed among the loudspeakers applied for reproduction.

The latter approach requires an appropriate \emph{panning law}, describing how the individual loudspeaker signals are obtained from the object source signal, ensuring that in the reproduced field the given audio object is perceived by the listener with desired spatial characteristics (e.g. object position, apparent width, etc.) \cite{Pulkki2001a, Pulkki2001b}.
Traditional stereophonic panning techniques included applying either interchannel intensity difference or time delay between the signals of the loudspeakers.
These techniques are commonly referred to as \emph{intensity stereophony}/\emph{amplitude panning} and \emph{time-based stereophony} respectively.
Ultimately both approaches control the apparent virtual audio object's position by adjusting the interaural time difference between the listener's ears (meaning that even amplitude difference between the loudspeaker signals is converted to time difference at the ears).

Originally both interchannel amplitude and time differences, ensuring correct localization were defined based on experimental data \cite{deBoer1940, Leakey1956, lipshitz1985stereo, Hugonnet1997, Rumsey2001}.	
Later the physically motivated \emph{sine law} \cite{Bauer1961, Rabenstein2007} and the \emph{tangent law of panning}\cite{Bennett1985, Rabenstein2007} emerged for the derivation of the required loudspeaker gains, based on an analytical model of stereophonic reproduction.
The latter one is discussed within the context of the introduced theoretical framework in the present thesis.
Recently amplitude panning was extended towards 3D spatial audio by Vector Base Amplitude Panning (VBAP) introduced by Pulkki \cite{Pulkki1997}, allowing the positioning of phantom/virtual sources in the 3D space by distributing its excitation signal between loudspeaker triplets \footnote{VBAP can be applied for loudspeaker pairs as well, in which case the formulation is equivalent with the tangent law of stereophony.}.

\paragraph{Ambisonics:}
As an alternative for stereophony the theory of Ambisonics was introduced by Gerzon in the 1970's, proposing both a novel recording and reproduction system \cite{gerzon1973periphony} and later elaborating an objective evaluation methodology for Ambisonic type sound systems \cite{gerzon1992general}.
Being an intermediate approach between stereophony and sound field synthesis, traditional Ambisonics aims at the reproduction of physical properties of a sound field in the proximity of a fixed listening position.

Generally speaking Ambisonics represents a sound field in terms of its orthogonal decomposition over a sphere, so that the sound scene to be reproduced is described and stored as coefficients of the orthogonal basis functions.
The orthogonal basis for Ambisonics is given by the set of spherical harmonics.
The so-called encoding step of Ambisonics format is therefore the decomposition of the sound field to be reproduced into a series of spherical harmonics up to a given order $N$, with the order defining the spatial resolution, and the size of the receiver zone for the representation \cite{gerzon1985ambisonics}.
Ambisonics signals hence are time histories belonging to given spherical harmonic shapes.

Traditional Ambisonics considered only spherical harmonics up to the first order ($N = 1$) \cite{gerzon1975the}, while modern microphone array designs allow the capturing of the sound field to be reproduced at a higher resolution with the technique termed as Higher Order Ambisonics (HOA, $N \geq 2$) \cite{5745011, 5744968, 5356221}.
Similarly to stereophony, besides measuring the target sound field at a predefined listener position, Ambisonics allows the rendering of virtual audio objects defined by a physical model:
once a model for the spatial characteristics of the virtual audio object is available, spherical harmonic decomposition may be performed analytically resulting in Ambisonics coefficients up to an arbitrary order \cite{4517624, Ahrens2010phd}.

Finally, at the reproduction, or decoding stage the loudspeaker signals for the actual loudspeaker layout are decoded from the spherical harmonics coefficients following some suitable decoding strategy \cite{Daniel2000:phd, Daniel2003b, zotter:hal-01106738, zotter2012all}.
Applying a decoding strategy that takes the actual reproduction loudspeaker characteristics into consideration is termed as Near-Field Compensated Higher Order Ambisonics (NFC-HOA) \cite{Daniel2003}.

\begin{figure}  
\small
  \begin{minipage}[c]{0.64\textwidth}
	\begin{overpic}[width = 1\columnwidth ]{Figures/Introduction/sfs_aim.png}
	\small
	\put(60,30){listening region}
	\put(0,45){\parbox{.5in}{virtual audio object}}
	\put(45,7){loudspeaker array}
	\end{overpic}   \end{minipage}\hfill
	\begin{minipage}[c]{0.3\textwidth}
    \caption{The general geometry for Sound Field Synthesis: the goal of synthesis is to reproduce the physical properties of a virtual sound object, or primary source of sound inside a control region, bounded by a densely spaced loudspeaker ensemble.}
\label{fig:introduction:sfs_aim}  \end{minipage}
\end{figure}

\paragraph{Sound field synthesis:}
An important property of spherical harmonic decomposition of a given sound field around a fixed point---practically around the listener's position---that increasing the decomposition order increases the area/volume at which the sound field is represented correctly, overcoming the sweet spot limitation of stereophony.
This fact adumbrates the motivation behind physically based sound field reproduction methods, commonly referred to as \emph{Sound Field Synthesis techniques}, or \emph{holophony} synthesizing the physical properties of a desired sound field over an extended listening area inherently ensures that the listener perceives the desired perceptual properties within the control region \cite{Spors2013:Survey}.
Obviously, controlling the sound field over an extended region requires numerous loudspeakers, positioned on the boundary of the control region.
Hence, these techniques are often referred to as \emph{massive multichannel sound reproduction methods} \cite{Spors2013:Survey, Zhang2017}.

Generally speaking, the Sound Field Synthesis problem is an inverse problem: the synthesized sound field is described analytically in the form of an integral/summation of the individual loudspeakers' sound field, used for reproduction \cite{Ahrens2010phd, Ahrens2012, fazi2008surround, Fazi2010}.
In order to derive analytical loudspeaker signals this integral formulation has to be solved in an inverse manner for any target virtual sound field.
The solution is available explicitly only in special geometries: for a spherical and circular arrangement of loudspeakers the direct solution is proven to coincide with NFC-HOA \cite{Daniel2003, fazi2008surround, Fazi2010, poletti2005three, 943347, Ahrens2008:Analytical_Circ_Spherical_SFS, Ahrens2011:icassp}, while for a theoretical infinite planar or linear distribution of loudspeakers the solution is known as the \emph{Spectral Division Method (SDM)} \cite{Ahrens2010a, Ahrens2012:Ambisonics_for_planar_linear, Ahrens2012}.
NFC-HOA and SDM are therefore commonly referred to as the \emph{explicit solution} for the sound field synthesis problem.

Besides NFC-HOA and SDM the most prominent, well-known sound field synthesis approach is Wave Field Synthesis, the main subject of the present dissertation.
Wave Field Synthesis (WFS) aims to recreate the desired sound field---or more precisely the desired wavefronts---by putting the Huygens-principle into practice: 
each reproduction loudspeaker acts as the source of a secondary wavefront, so that the resultant field of the entire speaker arrangement coincides with that of a virtual sound source \cite{Berkhout1993:Acoustic_control_by_WFS, Verheijen1997:phd, Ahrens2012}.
As WFS yields driving signals from the local behaviour of the virtual sound field at the position of the loudspeakers it is often termed as a \emph{local solution} to the SFS problem.
On the other hand the explicit solutions compute the driving signal for a single loudspeaker from the global description of the virtual field, therefore NFC-HOA and SDM are termed as \emph{global solutions}.
Furthermore, since WFS extracts the loudspeaker driving signals from an appropriate boundary integral representation of sound fields, containing the solution implicitly, WFS is referred to as an \emph{implicit solution}.

\paragraph{Categorization of spatial audio techniques:}
As a summary of the foregoing the above described spatial audio techniques may be categorized based on the representation of the virtual sound scene to be reproduced \cite{Spors2013:Survey}
\begin{itemize}
\item \emph{Channel-based representation} is the most widely used method up to nowadays, storing and transmitting directly the driving signals of the loudspeakers used for reproduction.
Traditional stereophonic methods like Dolby stereo, 5.1, 7.1 are commonly channel-based formats with the drawback of reproducing the desired spatial characteristics only by applying a predefined, often standardized loudspeaker layout.
%
\item \emph{Object-based representation} stores the desired virtual sound scene in terms of the virtual audio object properties: the time history of the individual auditory events along with their spatial characteristics as metadata (position, source width, etc.).
Obviously, the decoding/reproduction stage requires the rendering of the loudspeaker driving signal for the actual loudspeaker layout, for which either VBAP, Wave Field Synthesis or simple stereophonic panning laws may be used.
%
\item As a third possibility, \emph{transform-based representation} stores the characteristics of the sound scene in terms of its coefficients for the expansion into  orthonormal spatial basis functions.
Similarly to the object-based case, a sophisticated decoding/rendering stage is required at the reproduction side in order to derive the driving signals for the loudspeaker arrangement, for which either NFC-HOA or the Spectral Division Method may be applied.
\end{itemize}

Due to the simplicity of the reproduction stage, up to the recent years commercially available technologies almost exclusively utilized channel-based representations,
however in the recent years object-based reproduction techniques have started to gain more ground.
Dolby Atmos and DTS-X are the first commercially successful object-based surround sound technologies, both realizing object-based stereophony \cite{Atmos}.
As the next step, the 3D audio coding part of the latest MPEG-H coding standard allows for standardized encoding, transmission and decoding of spatial audio scenes \cite{herre2015mpeg, 7056445}:
the standard audio decoder is capable of decoding either channel-based, object-based, or transform-based representations of the desired audio scene.
Object-based rendering is performed by Vector-based Amplitude Panning, while transform-based representation is realized by a standardized Higher-Order Ambisonics encoder and decoder.

Since several years Wave Field Synthesis based sound systems are available commercially with the introduction of the IOSONO and Sonic Emotion systems, even though that no complete unified WFS theory has been existed so far:
previous WFS approaches deal with the reproduction of specific sound object models applying specific loudspeaker geometries with well-defined control regions.
These limitations are overcome in the present thesis by presenting a generalized Wave Field Synthesis approach.
In the followings, first a brief overview on Wave Field Synthesis history is given, with highlighting the deficiencies of its theory that motivated the research, summarized in the present dissertation.

\section{Wave Field Synthesis history and motivation of the presented research:}
\begin{figure}
	\small
	\centering
	\begin{overpic}[width = .7\columnwidth]{Figures/Introduction/huygens_wfs.png}
	\put(31,3){primary wavefront}
	\put(14,45){\parbox{.5in}{secondary wavefronts}}
	\put(60,30){listening region}
	\end{overpic}
	\caption{Reproduction of a primary wavefront based on the Huygens-principle.}
	\label{Fig:intro:huygens_wfs}
\end{figure}

Huygens' principle states that each point on a primary wavefront at a given time instant acts as the source of spherical wavelets and the sum of these secondary waves determine the form of the original wavefront at any subsequent time \cite{Huygens1690}.
Hence if secondary sources of sound are present in the space covering a part of the primary wavefront, then the primary field can be reconstructed as the sum of the secondary wavefronts.
The idea of synthesizing wavefronts with loudspeakers based on the Huygens principle in order to reconstruct wave fields over an extended listening area dates back to the 1930's, to the concept of the \emph{acoustic curtain} by Steinberg and Snow \cite{Steinberg1934}.
They intuitively stated that an auditory scene could be recorded, transmitted and reproduced by recording the sound scene with a large, densely spaced microphone array and playing back with the same amount of loudspeakers located in the same arrangement as the microphones, at the reproduction venue \footnote{In fact, Snow termed the acoustic curtain concept as an ideal stereophonic system \cite{7254953}.}.
The concept is illustrated in figure \ref{Fig:intro:huygens_wfs}.
Due to the obvious technical constraints of that time the concept has not been put into practical application until the 1980's.

The original theory of Wave Field Synthesis---often referred to as \emph{traditional WFS}---evolved from the works of Berkhout et al. at the Technical University of Delft utilizing concepts, well-known in the field of seismic migration.%, applied for sound field control.
The basis of WFS theory were the Rayleigh integrals, the mathematical form of the Huygens' principle, representing a sound field as the sum of spherical waves emerging from an infinite plane.
Berkhout applied the stationary phase method (SPA) to the Rayleigh integrals in order to arrive at loudspeaker driving signals for a linear array of loudspeakers instead of the practically infeasible planar array.
The original formulation provided driving signals for loudspeakers with dipole characteristics \cite{Berkhout1988, Berkhout1993:Acoustic_control_by_WFS}---soon extended for monopole loudspeaker models as well \cite{doi:10.1121/1.404755, Vogel1993:phd, devries1994the, Start1997:phd, Verheijen1997:phd, deBrujin2004}---, reproducing the wavefront of a virtual spherical wave in the horizontal plane, containing the loudspeaker array.
It was understood that the dimensionality reduction performed by the SPA restricts the amplitude correct reproduction to a control curve in the plane of synthesis, termed here as the reference curve \cite{sonke1998variable}.
For traditional WFS this reference curve was usually chosen to be a reference line, parallel with the loudspeaker arrangement.
The theoretical framework of traditional WFS has been extended towards various aspects, including the consideration of loudspeaker directivity \cite{devries1996sound, Firtha2012:isma}, stochastic loudspeaker properties \cite{Firtha2013:daga, Firtha2013:internoise}, application of curved arrays \cite{start1996application}, synthesis of extended and directive sources \cite{Corteel2007, Baalman2008:phd}, the perceptual aspects of synthesis \cite{Wittek2007:phd, Corteel2006:phd, Hulsebos2004:phd, wittek2004spatial, strauss2004generation} or the inclusion of the reproduction room's effects to the WFS theory \cite{spors2003an, corteel2003listening, 1326755, buchner2004efficient, petrausch2005simulation}.
Traditional WFS was also the subject of various research projects, most notably the CARROUSO project, aiming at the integration of the technique into the MPEG-4 standard \cite{sporer2001carrouso}. 
This endeavor was not realized eventually, but two "spin-off" companies of the project, the IOSONO and Sonic Emotion are still offering commercially available WFS systems nowadays.

The latest milestone in Wave Field Synthesis theory were the works of Spors et al., generalizing WFS towards the synthesis of an arbitrary analytically available sound field, applying an arbitrary shaped loudspeaker contour \cite{Spors2008:WFSrevisited, Rabenstein2007}.
The presented loudspeaker driving signals allowed the synthesis of general 2-dimensional sound field, ensuring amplitude correct synthesis at a single reference point,
allowing the reproduction of complex virtual sound scene, e.g. the field, generated by a moving sound source \cite{Ahrens2008moving, Ahrens2008moving_b, Ahrens2011_moving_source_WFS}.
The method however---since it derived driving signals from the 2D Rayleigh integral---failed to control the amplitude of general 3D sound fields.
Furthermore, the exact connection between traditional and the latter \emph{revisited WFS} formulations has not been known so far.

\vspace{3mm}
The present dissertation revisits the theoretical basics of Wave Field Synthesis.
First, several high frequency acoustic concepts are introduced---e.g the local wavenumber vector and the local wavefront curvature---being beneficial for the deeper understanding of the results, concerning WFS.
By using these concepts brief and physically illustrative loudspeakers driving functions are derived.
These driving functions allow the reproduction of arbitrary two, or three-dimensional sound fields applying an arbitrary shaped ensemble of loudspeakers with the amplitude of the synthesized field optimized along an arbitrary reference curve.
Hence, the presented theoretical framework includes previous WFS approaches as special cases.

The introduced high frequency concepts are well-known in the field of high frequency acoustics and ray acoustics.
This indicates the important fact that WFS can be regarded as the ray tracing, or ray-based solution of the general sound field synthesis problem---which is a key message of the present work---, realizing the matching of the virtual source's and the secondary loudspeakers' wavefronts at the predefined reference positions \footnote{It should be noted that in some of the early works of Berkhout termed the technique as Wave Front Synthesis \cite{berkhout1992wave, doi:10.1121/1.404755} which terminology may be more expressive, reflecting the underlying physical interpretation of the solution.}.
This fact is also confirmed in the present thesis by showing that WFS is the high frequency, ray based approximation of the explicit, direct solution for the sound field synthesis problem.
This connection of WFS techniques and the explicit SFS solution has been investigated only for particular virtual source models in the related literature, e.g. for the case of a virtual spherical wave \cite{Spors2010:analysis_and_improvement} and for a virtual plane wave \cite{Schultz2016:DAGA}.

Finally, as a complex application example for the presented framework the reproduction of moving virtual sources is investigated in details.
The reproduction of moving sources has been the subject of studies since the early age of WFS theory, as an obvious need when dynamic sound scenes are to be synthesized.
Early formulations attempted to synthesize the field of a moving point source by applying the traditional WFS driving signals with changing the virtual source position as the function of time.
This approach however failed to properly recreate Doppler effect, leading to serious artifacts in the synthesized field as investigated in details by Franck et al. \cite{Franck2007}.
Ahrens et al. used the revisited WFS formulation in order to recreate the field of a moving source \cite{Ahrens2008moving, Ahrens2008moving_b, Ahrens2012}.
However, due to physical constrains of revisited WFS theory, it failed to control the amplitude of the synthesized source.
In the present work the physically correct loudspeaker driving signals are presented for the synthesis of moving sources of sound, applying either WFS or  the explicit solution, termed the Spectral Division Method.

With highlighting the related publications by the author, the thesis is structured as follows
\begin{itemize}
\item Chapter \ref{sec:general_wave_theory} gives an overview on basic acoustic concepts, required for dealing with the general Sound Field Synthesis problem.
Different descriptions of sound fields are discussed, including spectral integral and boundary integral representations.
%
\item Chapter \ref{sec:high_freq_approx} introduces important high frequency concepts---the local wavenumber  vector local wavefront curvature and the high frequency gradient approximation---which are later applied in order to explain results, concerning the \emph{stationary phase approximation (SPA)} of integrals.
The SPA is of central importance in the aspect of the present thesis: loosely speaking the present work discusses how integral representations can be manipulated by the SPA in order to extract the desired SFS driving signals from them.
The application of the SPA to the different integral representations is discussed via examples.
Some of the results in these examples---describing wave dynamics by investigating the sound field's phase function and its derivatives---are well-known in the field of ray acoustics, however the present thesis introduces a novel approach for their derivation, so far unknown in the related literature.
%
\item Chapter \ref{sec:sound_field_synthesis} deals with the solution of the general Sound Field Synthesis problem.
By applying the SPA to the boundary integral representation of wave fields	 a unified Wave Field Synthesis framework is introduced, capable of the synthtesis of an arbitrary sound field applying arbitrary shaped loudspeaker ensembles, with optimizing the synthesis on a pre-defined reference curve \cite{Firtha2016, schultz2017wave}.
The application of the presented concepts are illustrated with examples, highlighting how previous WFS approaches are included inherently in the present framework.
By applying asymptotic approximation to the Spectral Division Method a novel SFS method is introduced, ensuring wavefront matching along a control curve requiring merely the virtual field measured at these control points \cite{Firtha2017:daga}.
Finally, it is highlighted, that the proposed method is equivalent with WFS, indicating the general relation between the implicit and the explicit SFS methods \cite{Firtha2018:WFS_vs_SDM}.
Finally, the effect of the discrete secondary source source distribution (instead of the theoretical continuous one) is discussed, and a novel antialiasing strategy is introduced \cite{Firtha2018_daga_a}.
%
\item As a detailed, complex example for the above theoretical results, in Chapter \ref{sec:moving_source_synthesis} the reproduction of moving virtual sources is investigated.
By adapting the unified WFS theory to the analytical description of sources under motion, driving signals are presented for an arbitrary contour of loudspeakers \cite{Firtha2015:daga, firtha2016wave, doi:10.1121/1.4996126}.
Besides Wave Field synthesis, the explicit solution is also presented, serving as a reference solution \cite{Firtha2014:daga, Firtha2014:isma}.
Finally, several practical aspects of synthesis are discussed, evolving at the practical application of the presented driving functions, e.g. numerical calculation of the presented analytical driving functions and the effects of the applied loudspeaker geometry \cite{Firtha2018_daga_a}.
For this latter question the explicit solution---for which WFS constitutes a high-frequency approximation similarly to the case of stationary sound scenes \cite{firtha2015sound}---is utilized to the analytical investigation of the evolving artifacts \cite{firtha2016:daga}.
\end{itemize}
